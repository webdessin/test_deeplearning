{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RecommendationSystemWithDoc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOwar7b+LlughuTDt5XS4y7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "buAjIKu3i6ay"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDY34VdFjOqt"
      },
      "source": [
        "df_data = pd.read_csv('./data.csv', index_col=0)\n",
        "df_data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-TQ0Wwr4jOnw"
      },
      "source": [
        "df_data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKw6e1PIjOlQ"
      },
      "source": [
        "df_data['Desc']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5ZtMqZOjOik"
      },
      "source": [
        "from nltk.tokenize import RegexpTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEJMuCiDjOf6"
      },
      "source": [
        "text01 = 'We know that power is shifting: From West to E'\n",
        "def remove_punctuation(text):\n",
        "  tokenizer = RegexpTokenizer('[a-zA-Z]+')                # 이렇게 하면 리스트로 나온다. 그리고 리스트를 space로 구분된 string으로 만들어줘야 한다. \n",
        "  text_list = tokenizer.tokenize(text)\n",
        "  # print(type(text_list), text_list)\n",
        "  result = ' '.join(text_list)\n",
        "  # print(type(result), result)\n",
        "  return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKDuMCN9jOdV"
      },
      "source": [
        "remove_punctuation(text01)                  # for text01 in df_data['Desc']: 과 같은 효과"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76TADTQ1jOav"
      },
      "source": [
        "df_data['cleaned'] = df_data['Desc'].apply(remove_punctuation) # apply 안에 함수를 넣어준다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g6GpoXeBjOYF"
      },
      "source": [
        "df_data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "op5PUN0hjOVj"
      },
      "source": [
        "df_data['cleaned'].head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWQimf3YjOTI"
      },
      "source": [
        "df_data.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeEKIjxTtyPT"
      },
      "source": [
        "## Pre-Trained"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_njgIU2jOQh"
      },
      "source": [
        "!curl -O https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H4hBcpkljOOA"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxi3wI6mjOLQ"
      },
      "source": [
        "corpus = []\n",
        "for words in df_data['cleaned']:\n",
        "  corpus .append(words.split())\n",
        "print(type(corpus), corpus[4:8])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXPhsjS4jOIw"
      },
      "source": [
        "word2vec_model = Word2Vec(min_count=2, workers=-1, size=300)\n",
        "word2vec_model.build_vocab(corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVKuqTcAjOGR"
      },
      "source": [
        "word2vec_model.intersect_word2vec_format('GoogleNews-vectors-negative300.bin.gz', lockf=1.0, binary=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PudEZNut71_"
      },
      "source": [
        "word2vec_model.train(df_data['cleaned'], total_examples=word2vec_model.corpus_count, epochs=15)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLsjwuZgt7zO"
      },
      "source": [
        "word2vec_model.wv.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8BpByflt7wO"
      },
      "source": [
        "doc_embedding_list = list()\n",
        "# for line in df_data['cleaned'][2:3]:\n",
        "for line in df_data['cleaned']:\n",
        "  # print(line)\n",
        "  doc2vec = None\n",
        "  for word in line.split():\n",
        "    # print(word)\n",
        "    if word in word2vec_model.wv.vocab:\n",
        "      # print(word2vec_model[word])\n",
        "      if doc2vec is None:\n",
        "        doc2vec = word2vec_model[word] \n",
        "      else :\n",
        "        doc2vec = doc2vec + word2vec_model[word] \n",
        "\n",
        "  if doc2vec is not None:\n",
        "    doc2vec = doc2vec / len(doc2vec)\n",
        "    doc_embedding_list.append(doc2vec)\n",
        "  # print(type(doc2vec), doc2vec.shape, doc2vec)\n",
        "\n",
        "print(doc_embedding_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx0ukV3Ht7te"
      },
      "source": [
        "type(doc_embedding_list), doc_embedding_list[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQIa-fdluD7A"
      },
      "source": [
        "## cosin matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IYtW_rBuC5-"
      },
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Puu4aEWKuC3G"
      },
      "source": [
        "cosine_sim = cosine_similarity(doc_embedding_list, doc_embedding_list)\n",
        "type(cosine_sim), cosine_sim.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUCiKHJEuC0e"
      },
      "source": [
        "cosine_sim[3]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8r8tXxmuImI"
      },
      "source": [
        "## Predict"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q3iU_N2uKUO"
      },
      "source": [
        "# title = 'The Da Vinci Code'\n",
        "title = 'The Four Pillars of Investing'   # 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fx4gWQ3vuOeJ"
      },
      "source": [
        "idx = 3\n",
        "sim_scores = list(enumerate(cosine_sim[3]))\n",
        "print(sim_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEiXMfLPuObS"
      },
      "source": [
        "sim_scores_list = sorted(sim_scores, key=lambda x:x[1], reverse=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xJNgf8FuOYj"
      },
      "source": [
        "sim_scores_list[1:6]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SUlqT0HuTEb"
      },
      "source": [
        "df_data.head(7)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}